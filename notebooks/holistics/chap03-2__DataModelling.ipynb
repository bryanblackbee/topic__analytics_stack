{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 3: Data Modelling for Analytics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kimball's Dimensional Data Modelling\n",
    "\n",
    "### Key Concept 1: The Star Schema\n",
    "\n",
    "The star schema consists of two types of tables:\n",
    "- The **Fact Table** which stores measures of a business process\n",
    "- The **Dimension Table** which stores descriptions of the associated fact tables\n",
    "\n",
    "The general layout is to have the Fact Tables surrounding the Dimension Tables, forming the aptly named \"Star Schema\" design. Also, as a rule of thumb, the Dimension Tables are more slow moving while the Fact Tables are much faster moving.\n",
    "\n",
    "For example, \n",
    "\n",
    "- in a POS system, there could be `Product Dimension` and `Customer Dimension`, and they have associated `Order Fact` tables. \n",
    "- in a HR / applications management system, there could be an `Employee Dimension`, a `Role/Position Dimension`, followed by `Application Fact` tables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To develop a star schema, we follow the four steps of data modelling:\n",
    "\n",
    "1. Select a business process to model. What are the inputs and outputs and what does the business intend to measure?\n",
    "2. Select the grain. What is the atomic level of data (the level where objects cannot be split further) you want to measure? \n",
    "3. Identify the Dimensions. What are the descriptive contexts of the grain you want to capture? Note that this can also include externally determined dimensions like temporal attributes (year, month, week, day, day of week, week no. quarter no. etc.)\n",
    "4. Identify the Facts. What are the numeric performance indicators you want to capture about the dimension?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kimball Modelling, then and now\n",
    "\n",
    "Some important concepts to keep in mind today because of the technology considerations today:\n",
    "\n",
    "1. Storage is cheap\n",
    "2. Compute is cheap\n",
    "3. Engineering time is expensive\n",
    "\n",
    "**Example 1: Inventory Management**\n",
    "\n",
    "Previously, when trying to manage inventory movements, Kimball proposed to implement \"snapshot\" tables taken periodically and perform aggregation across snapshots. However, with cheaper storage, we can get away by storing daily dumps of facts.\n",
    "\n",
    "**Example 2: Slowly Changing Dimensions**\n",
    "\n",
    "Previously, if a dimension table changes, there could be multiple ways to handle this change:\n",
    "\n",
    "1. Type 1: Update the column of the dimension directly\n",
    "2. Type 2: Add a new row to the dimension table, with a newer version and updated column value\n",
    "3. Type 3: Add a new column to the dimension table to store the updated value, while retaining the old value in the current column\n",
    "\n",
    "Today, we can use a Partitioning feature to store periodic (e.g. daily, monthly) snapshots of a dimension, and it is much easier intuitively to compare the same row in the same dimension across different time periods."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "In conclusion, the book argues that Kimball's concepts are still very relevant. We can still create adhoc queries for reports, or for POCs. But when certain features can be combined, we argue to remodel the process using Kimball's techniques.\n",
    "\n",
    "We can still leverage on data modelling tools to annotate data, and can still rely on SQL to perform simple ELT of data in a data warehouse. Ideally, developing a capability that leverages on technology and relies on less manpower, with more self-service tools at hand today, is more efficient.\n",
    "\n",
    "The goal of modelling is self-service. That means all the required data, business logic & presentation logic are all captured within the data modelling tool, and that will ensure that insights are delivered to the business unit timely & accurately."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
